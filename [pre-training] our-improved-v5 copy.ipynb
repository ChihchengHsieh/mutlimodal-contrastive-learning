{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mike8\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\_contextlib.py:125: UserWarning: Decorating classes is deprecated and will be disabled in future versions. You should only decorate functions or methods. To preserve the current behavior of class decoration, you can directly decorate the `__init__` method and nothing else.\n",
      "  warnings.warn(\"Decorating classes is deprecated and will be disabled in \"\n"
     ]
    }
   ],
   "source": [
    "from ds.physio.general import PhysioNetClinicalDataset\n",
    "import warnings, torch, os\n",
    "import pandas as pd\n",
    "import torch.utils.data as data\n",
    "from utils.train import get_dataloader_g, collate_fn\n",
    "from utils.device import clean_memory_get_device\n",
    "from utils.plot import plot_train\n",
    "from our_improved_v5.builder import OurImproved_v5\n",
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CUDA]\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n",
    "device = clean_memory_get_device()\n",
    "# device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "# def collate_fn(x):\n",
    "#     imgs = [i[0] for i in x]\n",
    "#     clinical = torch.stack([i[1] for i in x])\n",
    "#     return imgs, clinical\n",
    "\n",
    "train_d = data.DataLoader(\n",
    "    PhysioNetClinicalDataset(split_str=\"train\", image_size=image_size),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=None,\n",
    "    generator=get_dataloader_g(0),\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = OurImproved_v5(\n",
    "    models.resnet18,\n",
    "    clinical_input_dim=train_d.dataset.num_clinical_features(),\n",
    "    image_size=image_size,\n",
    "    # hidden_layer=\"avgpool\",  # layer name where output is hidden dimension. this can also be an integer specifying the index of the child\n",
    "    # project_hidden=True,  # use projection head\n",
    "    dim=512,  # output size of resnet18, to match size in the simclr.\n",
    "    pred_dim=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load 100 epoch model\n",
    "# cp = torch.load(os.path.join(\"checkpoints\", \"our_alt\", \"model\"), map_location=device)\n",
    "# learner.load_state_dict(cp[\"model\"], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingWarmRestarts\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=[p for p in learner.parameters() if p.requires_grad],\n",
    "    lr=3e-4,\n",
    ")\n",
    "\n",
    "# scheduler = StepLR(\n",
    "#     optimizer,\n",
    "#     step_size=1,\n",
    "#     gamma=0.85,\n",
    "# )\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=math.ceil(len(train_d.dataset) / batch_size)\n",
    "    * epochs,  # 286,817 is the size of the training dataset. (https://paperswithcode.com/dataset/cnn-daily-mail-1)\n",
    "    eta_min=1e-8,\n",
    ")\n",
    "# scheduler = CosineAnnealingWarmRestarts(\n",
    "#     optimizer,\n",
    "#     T_0=10,\n",
    "#     T_mult=2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_loss_dict(loss_dict: list[dict[str, float]]):\n",
    "    keys = loss_dict[0].keys()\n",
    "    out_dict = {k: [i[k] for i in loss_dict] for k in keys}\n",
    "    out_dict = {k: np.mean(v) for k, v in out_dict.items()}\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model,\n",
    "    optimizer,\n",
    "    data_loader,\n",
    "    device,\n",
    "    epoch,\n",
    "    max_norm=0,\n",
    "    lr_scheduler=None,\n",
    "):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    iters = math.ceil(len(data_loader.dataset) / train_d.batch_size)\n",
    "\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1.0 / 1000\n",
    "        warmup_iters = min(1000, iters - 1)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "            optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
    "        )\n",
    "\n",
    "    losses = []\n",
    "    loss_dict = []\n",
    "\n",
    "    is_wr = (not lr_scheduler is None) and isinstance(\n",
    "        lr_scheduler, torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
    "    )\n",
    "    \n",
    "    pbar = tqdm(total=len(data_loader))\n",
    "    \n",
    "    for i, (img, tab) in enumerate(data_loader):\n",
    "        loss, l_d = model(img.to(device), tab.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if max_norm > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        # if is consinwr, step every batch\n",
    "        if (not lr_scheduler is None) and is_wr:\n",
    "            # print(\"CosineAnnealingWarmRestarts learning rate update.\")\n",
    "            lr_scheduler.step(epoch + i / iters)\n",
    "        elif epoch == 0:\n",
    "            # print(\"Warmup scheduler stepping\")\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        loss_dict.append(l_d)\n",
    "        pbar.update()\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # scheduler step after an epoch if not cosinewr\n",
    "    if epoch != 0 and (lr_scheduler is not None) and not is_wr:\n",
    "        # print(\"Epoch scheduler stepping\")\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    return losses, {**get_mean_loss_dict(loss_dict), \"lr\": lr_scheduler.get_last_lr()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 30/451 [02:04<24:10,  3.45s/it]"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "sub_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_l, sub_l = train_one_epoch(\n",
    "        learner,\n",
    "        optimizer,\n",
    "        train_d,\n",
    "        device,\n",
    "        epoch,\n",
    "        max_norm=1,\n",
    "        lr_scheduler=scheduler,\n",
    "    )\n",
    "    sub_losses.append(sub_l)\n",
    "    train_losses.append(np.mean(train_l))\n",
    "    clear_output()\n",
    "    plot_train(train_losses, title=\"Loss\")\n",
    "    for k in sub_losses[0].keys():\n",
    "        plot_train([s[k] for s in sub_losses], title=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"our_improved_v5\" \n",
    "\n",
    "saving_dict = {\"model\": learner.state_dict()}\n",
    "if optimizer:\n",
    "    saving_dict[\"optimizer\"] = optimizer.state_dict()\n",
    "\n",
    "if scheduler:\n",
    "    saving_dict['scheduler'] = scheduler.state_dict()\n",
    "\n",
    "saving_folder = os.path.join(\"checkpoints\", model_path)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(saving_folder, exist_ok=True)\n",
    "torch.save(\n",
    "    saving_dict,\n",
    "    os.path.join(\"checkpoints\", model_path, \"model\"),\n",
    ")\n",
    "\n",
    "# learner.net.net.state_dict() # resnet here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

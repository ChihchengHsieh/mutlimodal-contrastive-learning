{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {\n",
    "    \"supervised\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5584009993753903,\n",
    "            \"precision\": 0.614010989010989,\n",
    "            \"accuracy\": 0.889010989010989,\n",
    "            \"recall\": 0.5120274914089347,\n",
    "            \"auc\": 0.7304543496702668,\n",
    "            \"top-1-acc\": 0.8890,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.3575510204081632,\n",
    "            \"precision\": 0.6221590909090909,\n",
    "            \"accuracy\": 0.8764521193092621,\n",
    "            \"recall\": 0.2508591065292096,\n",
    "            \"auc\": 0.6133320455331149,\n",
    "            \"top-1-acc\": 0.8765,\n",
    "        },\n",
    "    },\n",
    "    # \"simclr\": {\n",
    "    #     \"fine_tuned\": {\n",
    "    #         \"f1\": 0.5612499999999999,\n",
    "    #         \"precision\": 0.6176066024759285,\n",
    "    #         \"accuracy\": 0.889795918367347,\n",
    "    #         \"recall\": 0.5143184421534936,\n",
    "    #         \"auc\": 0.7318727011567905,\n",
    "    #         \"top-1-acc\": 0.8898,\n",
    "    #     },\n",
    "    #     \"linear_eval\": {\n",
    "    #         \"f1\": 0.4553846153846154,\n",
    "    #         \"precision\": 0.6932084309133489,\n",
    "    #         \"accuracy\": 0.8888540031397174,\n",
    "    #         \"recall\": 0.33906071019473083,\n",
    "    #         \"auc\": 0.6576147647753717,\n",
    "    #         \"top-1-acc\": 0.8889,\n",
    "    #     },\n",
    "    # },\n",
    "    \"simsiam\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.545565749235474,\n",
    "            \"precision\": 0.5853018372703412,\n",
    "            \"accuracy\": 0.8833594976452119,\n",
    "            \"recall\": 0.5108820160366552,\n",
    "            \"auc\": 0.7266980573179456,\n",
    "            \"top-1-acc\": 0.8834,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.09891196834817012,\n",
    "            \"precision\": 0.36231884057971014,\n",
    "            \"accuracy\": 0.8569858712715855,\n",
    "            \"recall\": 0.0572737686139748,\n",
    "            \"auc\": 0.5206325182891596,\n",
    "            \"top-1-acc\": 0.8570,\n",
    "        },\n",
    "    },\n",
    "    \"byol\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5630461922596754,\n",
    "            \"precision\": 0.6186556927297668,\n",
    "            \"accuracy\": 0.8901098901098901,\n",
    "            \"recall\": 0.5166093928980527,\n",
    "            \"auc\": 0.73301817652907,\n",
    "            \"top-1-acc\": 0.8901,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.34856175972927245,\n",
    "            \"precision\": 0.6666666666666666,\n",
    "            \"accuracy\": 0.8791208791208791,\n",
    "            \"recall\": 0.23596792668957617,\n",
    "            \"auc\": 0.6086152167557395,\n",
    "            \"top-1-acc\": 0.8791,\n",
    "        },\n",
    "    },\n",
    "    \"twins\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5631901840490797,\n",
    "            \"precision\": 0.6063408190224571,\n",
    "            \"accuracy\": 0.8882260596546311,\n",
    "            \"recall\": 0.5257731958762887,\n",
    "            \"auc\": 0.735780903923227,\n",
    "            \"top-1-acc\": 0.8882,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.26548672566371684,\n",
    "            \"precision\": 0.5836575875486382,\n",
    "            \"accuracy\": 0.869701726844584,\n",
    "            \"recall\": 0.1718213058419244,\n",
    "            \"auc\": 0.5761780715129216,\n",
    "            \"top-1-acc\": 0.8697,\n",
    "        },\n",
    "    },\n",
    "    \"moco\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5830797321972002,\n",
    "            \"precision\": 0.6220779220779221,\n",
    "            \"accuracy\": 0.8924646781789639,\n",
    "            \"recall\": 0.5486827033218786,\n",
    "            \"auc\": 0.7478723685792583,\n",
    "            \"top-1-acc\": 0.8925,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.306896551724138,\n",
    "            \"precision\": 0.6202090592334495,\n",
    "            \"accuracy\": 0.8737833594976452,\n",
    "            \"recall\": 0.20389461626575028,\n",
    "            \"auc\": 0.5920328093153383,\n",
    "            \"top-1-acc\": 0.8738,\n",
    "        },\n",
    "    },\n",
    "    \"our\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5744814582023885,\n",
    "            \"precision\": 0.6364902506963789,\n",
    "            \"accuracy\": 0.8937205651491366,\n",
    "            \"recall\": 0.5234822451317297,\n",
    "            \"auc\": 0.7380009006266253,\n",
    "            \"top-1-acc\": 0.8937,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.35333333333333333,\n",
    "            \"precision\": 0.6483180428134556,\n",
    "            \"accuracy\": 0.8781789638932496,\n",
    "            \"recall\": 0.24284077892325315,\n",
    "            \"auc\": 0.6109601384156015,\n",
    "            \"top-1-acc\": 0.8782,\n",
    "        },\n",
    "    },\n",
    "    \"our-alt\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5777504609711125,\n",
    "            \"precision\": 0.623342175066313,\n",
    "            \"accuracy\": 0.8921507064364207,\n",
    "            \"recall\": 0.5383734249713631,\n",
    "            \"auc\": 0.7433544403372369,\n",
    "            \"top-1-acc\": 0.8922,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.41935483870967744,\n",
    "            \"precision\": 0.6363636363636364,\n",
    "            \"accuracy\": 0.8813186813186813,\n",
    "            \"recall\": 0.3127147766323024,\n",
    "            \"auc\": 0.6421678303754562,\n",
    "            \"top-1-acc\": 0.8813,\n",
    "        },\n",
    "    },\n",
    "    \"our-alt-200\": {\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.4340359094457455,\n",
    "            \"precision\": 0.6813725490196079,\n",
    "            \"accuracy\": 0.8861852433281004,\n",
    "            \"recall\": 0.31844215349369986,\n",
    "            \"auc\": 0.6473964451296041,\n",
    "            \"top-1-acc\": 0.8862,\n",
    "        },\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5910735826296742,\n",
    "            \"precision\": 0.6242038216560509,\n",
    "            \"accuracy\": 0.893563579277865,\n",
    "            \"recall\": 0.561282932416953,\n",
    "            \"auc\": 0.7538086483078035,\n",
    "            \"top-1-acc\": 0.8936,\n",
    "        },\n",
    "    },\n",
    "    \"our-improved-100\": {\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.37995149555375907,\n",
    "            \"precision\": 0.6456043956043956,\n",
    "            \"accuracy\": 0.8795918367346939,\n",
    "            \"recall\": 0.26918671248568155,\n",
    "            \"auc\": 0.622859683330343,\n",
    "            \"top-1-acc\": 0.8796,\n",
    "        },\n",
    "    },\n",
    "    \"our-improved-150\": {\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.37702265372168287,\n",
    "            \"precision\": 0.6418732782369146,\n",
    "            \"accuracy\": 0.8791208791208791,\n",
    "            \"recall\": 0.26689576174112256,\n",
    "            \"auc\": 0.6216232492533155,\n",
    "            \"top-1-acc\": 0.8791,\n",
    "        }\n",
    "    },\n",
    "    \"simclr\": {\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.35876623376623373,\n",
    "            \"precision\": 0.6155988857938719,\n",
    "            \"accuracy\": 0.8759811616954474,\n",
    "            \"recall\": 0.2531500572737686,\n",
    "            \"auc\": 0.6140227273816542,\n",
    "            \"top-1-acc\": 0.8760,\n",
    "        }\n",
    "    },\n",
    "    \"our-improved-v3\": {\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.326530612244898,\n",
    "            \"precision\": 0.6336633663366337,\n",
    "            \"accuracy\": 0.8756671899529043,\n",
    "            \"recall\": 0.21993127147766323,\n",
    "            \"auc\": 0.5998692195117987,\n",
    "            \"top-1-acc\": 0.8757,\n",
    "        }\n",
    "    },\n",
    "    \"our-improved-v4\": {\n",
    "        \"linear_eval\":{\n",
    "            \"f1\": 0.4123222748815166,\n",
    "            \"precision\": 0.6641221374045801,\n",
    "            \"accuracy\": 0.8832025117739404,\n",
    "            \"recall\": 0.29896907216494845,\n",
    "            \"auc\": 0.6374779870557323,\n",
    "            \"top-1-acc\": 0.8832,\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_eval_result_df = []\n",
    "for k, v in result_dict.items():\n",
    "    linear_eval_result_df.append(\n",
    "        {\n",
    "            \"algorithm\": k,\n",
    "            **v[\"linear_eval\"],\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_eval_result_df = pd.DataFrame(linear_eval_result_df)\n",
    "linear_eval_result_df.to_csv(\"[chexpert] linear_eval.csv\")\n",
    "\n",
    "# from the result, then we know our-alt may be the best algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>top-1-acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supervised</td>\n",
       "      <td>0.357551</td>\n",
       "      <td>0.622159</td>\n",
       "      <td>0.876452</td>\n",
       "      <td>0.250859</td>\n",
       "      <td>0.613332</td>\n",
       "      <td>0.8765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simsiam</td>\n",
       "      <td>0.098912</td>\n",
       "      <td>0.362319</td>\n",
       "      <td>0.856986</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.520633</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>byol</td>\n",
       "      <td>0.348562</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.879121</td>\n",
       "      <td>0.235968</td>\n",
       "      <td>0.608615</td>\n",
       "      <td>0.8791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twins</td>\n",
       "      <td>0.265487</td>\n",
       "      <td>0.583658</td>\n",
       "      <td>0.869702</td>\n",
       "      <td>0.171821</td>\n",
       "      <td>0.576178</td>\n",
       "      <td>0.8697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moco</td>\n",
       "      <td>0.306897</td>\n",
       "      <td>0.620209</td>\n",
       "      <td>0.873783</td>\n",
       "      <td>0.203895</td>\n",
       "      <td>0.592033</td>\n",
       "      <td>0.8738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>our</td>\n",
       "      <td>0.353333</td>\n",
       "      <td>0.648318</td>\n",
       "      <td>0.878179</td>\n",
       "      <td>0.242841</td>\n",
       "      <td>0.610960</td>\n",
       "      <td>0.8782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>our-alt</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.881319</td>\n",
       "      <td>0.312715</td>\n",
       "      <td>0.642168</td>\n",
       "      <td>0.8813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>our-alt-200</td>\n",
       "      <td>0.434036</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.886185</td>\n",
       "      <td>0.318442</td>\n",
       "      <td>0.647396</td>\n",
       "      <td>0.8862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>our-improved-100</td>\n",
       "      <td>0.379951</td>\n",
       "      <td>0.645604</td>\n",
       "      <td>0.879592</td>\n",
       "      <td>0.269187</td>\n",
       "      <td>0.622860</td>\n",
       "      <td>0.8796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>our-improved-150</td>\n",
       "      <td>0.377023</td>\n",
       "      <td>0.641873</td>\n",
       "      <td>0.879121</td>\n",
       "      <td>0.266896</td>\n",
       "      <td>0.621623</td>\n",
       "      <td>0.8791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>simclr</td>\n",
       "      <td>0.358766</td>\n",
       "      <td>0.615599</td>\n",
       "      <td>0.875981</td>\n",
       "      <td>0.253150</td>\n",
       "      <td>0.614023</td>\n",
       "      <td>0.8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>our-improved-v3</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.219931</td>\n",
       "      <td>0.599869</td>\n",
       "      <td>0.8757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>our-improved-v4</td>\n",
       "      <td>0.412322</td>\n",
       "      <td>0.664122</td>\n",
       "      <td>0.883203</td>\n",
       "      <td>0.298969</td>\n",
       "      <td>0.637478</td>\n",
       "      <td>0.8832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           algorithm        f1  precision  accuracy    recall       auc  \\\n",
       "0         supervised  0.357551   0.622159  0.876452  0.250859  0.613332   \n",
       "1            simsiam  0.098912   0.362319  0.856986  0.057274  0.520633   \n",
       "2               byol  0.348562   0.666667  0.879121  0.235968  0.608615   \n",
       "3              twins  0.265487   0.583658  0.869702  0.171821  0.576178   \n",
       "4               moco  0.306897   0.620209  0.873783  0.203895  0.592033   \n",
       "5                our  0.353333   0.648318  0.878179  0.242841  0.610960   \n",
       "6            our-alt  0.419355   0.636364  0.881319  0.312715  0.642168   \n",
       "7        our-alt-200  0.434036   0.681373  0.886185  0.318442  0.647396   \n",
       "8   our-improved-100  0.379951   0.645604  0.879592  0.269187  0.622860   \n",
       "9   our-improved-150  0.377023   0.641873  0.879121  0.266896  0.621623   \n",
       "10            simclr  0.358766   0.615599  0.875981  0.253150  0.614023   \n",
       "11   our-improved-v3  0.326531   0.633663  0.875667  0.219931  0.599869   \n",
       "12   our-improved-v4  0.412322   0.664122  0.883203  0.298969  0.637478   \n",
       "\n",
       "    top-1-acc  \n",
       "0      0.8765  \n",
       "1      0.8570  \n",
       "2      0.8791  \n",
       "3      0.8697  \n",
       "4      0.8738  \n",
       "5      0.8782  \n",
       "6      0.8813  \n",
       "7      0.8862  \n",
       "8      0.8796  \n",
       "9      0.8791  \n",
       "10     0.8760  \n",
       "11     0.8757  \n",
       "12     0.8832  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_eval_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fine_tuned'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m fine_tuned_result_df \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m result_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      3\u001b[0m     fine_tuned_result_df\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m      4\u001b[0m         {\n\u001b[0;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m\"\u001b[39m: k,\n\u001b[1;32m----> 6\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfine_tuned\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[0;32m      7\u001b[0m         }\n\u001b[0;32m      8\u001b[0m     )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'fine_tuned'"
     ]
    }
   ],
   "source": [
    "fine_tuned_result_df = []\n",
    "for k, v in result_dict.items():\n",
    "    fine_tuned_result_df.append(\n",
    "        {\n",
    "            \"algorithm\": k,\n",
    "            **v[\"fine_tuned\"],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>top-1-acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supervised</td>\n",
       "      <td>0.558401</td>\n",
       "      <td>0.614011</td>\n",
       "      <td>0.889011</td>\n",
       "      <td>0.512027</td>\n",
       "      <td>0.730454</td>\n",
       "      <td>0.8890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simclr</td>\n",
       "      <td>0.561250</td>\n",
       "      <td>0.617607</td>\n",
       "      <td>0.889796</td>\n",
       "      <td>0.514318</td>\n",
       "      <td>0.731873</td>\n",
       "      <td>0.8898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simsiam</td>\n",
       "      <td>0.545566</td>\n",
       "      <td>0.585302</td>\n",
       "      <td>0.883359</td>\n",
       "      <td>0.510882</td>\n",
       "      <td>0.726698</td>\n",
       "      <td>0.8834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>byol</td>\n",
       "      <td>0.563046</td>\n",
       "      <td>0.618656</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>0.516609</td>\n",
       "      <td>0.733018</td>\n",
       "      <td>0.8901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twins</td>\n",
       "      <td>0.563190</td>\n",
       "      <td>0.606341</td>\n",
       "      <td>0.888226</td>\n",
       "      <td>0.525773</td>\n",
       "      <td>0.735781</td>\n",
       "      <td>0.8882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>moco</td>\n",
       "      <td>0.583080</td>\n",
       "      <td>0.622078</td>\n",
       "      <td>0.892465</td>\n",
       "      <td>0.548683</td>\n",
       "      <td>0.747872</td>\n",
       "      <td>0.8925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>our</td>\n",
       "      <td>0.574481</td>\n",
       "      <td>0.636490</td>\n",
       "      <td>0.893721</td>\n",
       "      <td>0.523482</td>\n",
       "      <td>0.738001</td>\n",
       "      <td>0.8937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>our-alt</td>\n",
       "      <td>0.577750</td>\n",
       "      <td>0.623342</td>\n",
       "      <td>0.892151</td>\n",
       "      <td>0.538373</td>\n",
       "      <td>0.743354</td>\n",
       "      <td>0.8922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>our-alt-200</td>\n",
       "      <td>0.591074</td>\n",
       "      <td>0.624204</td>\n",
       "      <td>0.893564</td>\n",
       "      <td>0.561283</td>\n",
       "      <td>0.753809</td>\n",
       "      <td>0.8936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     algorithm        f1  precision  accuracy    recall       auc  top-1-acc\n",
       "0   supervised  0.558401   0.614011  0.889011  0.512027  0.730454     0.8890\n",
       "1       simclr  0.561250   0.617607  0.889796  0.514318  0.731873     0.8898\n",
       "2      simsiam  0.545566   0.585302  0.883359  0.510882  0.726698     0.8834\n",
       "3         byol  0.563046   0.618656  0.890110  0.516609  0.733018     0.8901\n",
       "4        twins  0.563190   0.606341  0.888226  0.525773  0.735781     0.8882\n",
       "5         moco  0.583080   0.622078  0.892465  0.548683  0.747872     0.8925\n",
       "6          our  0.574481   0.636490  0.893721  0.523482  0.738001     0.8937\n",
       "7      our-alt  0.577750   0.623342  0.892151  0.538373  0.743354     0.8922\n",
       "8  our-alt-200  0.591074   0.624204  0.893564  0.561283  0.753809     0.8936"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fine_tuned_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

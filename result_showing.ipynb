{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {\n",
    "    \"Supervised\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5584009993753903,\n",
    "            \"precision\": 0.614010989010989,\n",
    "            \"accuracy\": 0.889010989010989,\n",
    "            \"recall\": 0.5120274914089347,\n",
    "            \"auc\": 0.7304543496702668,\n",
    "            \"top-1-acc\": 0.8890,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.34516928158546656,\n",
    "            \"precision\": 0.6183431952662722,\n",
    "            \"accuracy\": 0.8755102040816326,\n",
    "            \"recall\": 0.23940435280641467,\n",
    "            \"auc\": 0.6079685034907096,\n",
    "            \"top-1-acc\": 0.8755,\n",
    "        },\n",
    "    },\n",
    "    # \"simclr\": {\n",
    "    #     \"fine_tuned\": {\n",
    "    #         \"f1\": 0.5612499999999999,\n",
    "    #         \"precision\": 0.6176066024759285,\n",
    "    #         \"accuracy\": 0.889795918367347,\n",
    "    #         \"recall\": 0.5143184421534936,\n",
    "    #         \"auc\": 0.7318727011567905,\n",
    "    #         \"top-1-acc\": 0.8898,\n",
    "    #     },\n",
    "    #     \"linear_eval\": {\n",
    "    #         \"f1\": 0.4553846153846154,\n",
    "    #         \"precision\": 0.6932084309133489,\n",
    "    #         \"accuracy\": 0.8888540031397174,\n",
    "    #         \"recall\": 0.33906071019473083,\n",
    "    #         \"auc\": 0.6576147647753717,\n",
    "    #         \"top-1-acc\": 0.8889,\n",
    "    #     },\n",
    "    # },\n",
    "    \"SimSiam\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.545565749235474,\n",
    "            \"precision\": 0.5853018372703412,\n",
    "            \"accuracy\": 0.8833594976452119,\n",
    "            \"recall\": 0.5108820160366552,\n",
    "            \"auc\": 0.7266980573179456,\n",
    "            \"top-1-acc\": 0.8834,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.09891196834817012,\n",
    "            \"precision\": 0.36231884057971014,\n",
    "            \"accuracy\": 0.8569858712715855,\n",
    "            \"recall\": 0.0572737686139748,\n",
    "            \"auc\": 0.5206325182891596,\n",
    "            \"top-1-acc\": 0.8570,\n",
    "        },\n",
    "    },\n",
    "    \"BYOL\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5630461922596754,\n",
    "            \"precision\": 0.6186556927297668,\n",
    "            \"accuracy\": 0.8901098901098901,\n",
    "            \"recall\": 0.5166093928980527,\n",
    "            \"auc\": 0.73301817652907,\n",
    "            \"top-1-acc\": 0.8901,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.34856175972927245,\n",
    "            \"precision\": 0.6666666666666666,\n",
    "            \"accuracy\": 0.8791208791208791,\n",
    "            \"recall\": 0.23596792668957617,\n",
    "            \"auc\": 0.6086152167557395,\n",
    "            \"top-1-acc\": 0.8791,\n",
    "        },\n",
    "    },\n",
    "    \"Barlow Twins\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5631901840490797,\n",
    "            \"precision\": 0.6063408190224571,\n",
    "            \"accuracy\": 0.8882260596546311,\n",
    "            \"recall\": 0.5257731958762887,\n",
    "            \"auc\": 0.735780903923227,\n",
    "            \"top-1-acc\": 0.8882,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.26548672566371684,\n",
    "            \"precision\": 0.5836575875486382,\n",
    "            \"accuracy\": 0.869701726844584,\n",
    "            \"recall\": 0.1718213058419244,\n",
    "            \"auc\": 0.5761780715129216,\n",
    "            \"top-1-acc\": 0.8697,\n",
    "        },\n",
    "    },\n",
    "    \"MoCo\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5629179331306992,\n",
    "            \"precision\": 0.5997409326424871,\n",
    "            \"accuracy\": 0.88712715855573,\n",
    "            \"recall\": 0.5303550973654066,\n",
    "            \"auc\": 0.7370713089155576,\n",
    "            \"top-1-acc\": 0.8871,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.306896551724138,\n",
    "            \"precision\": 0.6202090592334495,\n",
    "            \"accuracy\": 0.8737833594976452,\n",
    "            \"recall\": 0.20389461626575028,\n",
    "            \"auc\": 0.5920328093153383,\n",
    "            \"top-1-acc\": 0.8738,\n",
    "        },\n",
    "    },\n",
    "    # \"our\": {\n",
    "    #     \"fine_tuned\": {\n",
    "    #         \"f1\": 0.5744814582023885,\n",
    "    #         \"precision\": 0.6364902506963789,\n",
    "    #         \"accuracy\": 0.8937205651491366,\n",
    "    #         \"recall\": 0.5234822451317297,\n",
    "    #         \"auc\": 0.7380009006266253,\n",
    "    #         \"top-1-acc\": 0.8937,\n",
    "    #     },\n",
    "    #     \"linear_eval\": {\n",
    "    #         \"f1\": 0.35333333333333333,\n",
    "    #         \"precision\": 0.6483180428134556,\n",
    "    #         \"accuracy\": 0.8781789638932496,\n",
    "    #         \"recall\": 0.24284077892325315,\n",
    "    #         \"auc\": 0.6109601384156015,\n",
    "    #         \"top-1-acc\": 0.8782,\n",
    "    #     },\n",
    "    # },\n",
    "    # \"our-alt\": {\n",
    "    #     \"fine_tuned\": {\n",
    "    #         \"f1\": 0.5777504609711125,\n",
    "    #         \"precision\": 0.623342175066313,\n",
    "    #         \"accuracy\": 0.8921507064364207,\n",
    "    #         \"recall\": 0.5383734249713631,\n",
    "    #         \"auc\": 0.7433544403372369,\n",
    "    #         \"top-1-acc\": 0.8922,\n",
    "    #     },\n",
    "    #     \"linear_eval\": {\n",
    "    #         \"f1\": 0.41935483870967744,\n",
    "    #         \"precision\": 0.6363636363636364,\n",
    "    #         \"accuracy\": 0.8813186813186813,\n",
    "    #         \"recall\": 0.3127147766323024,\n",
    "    #         \"auc\": 0.6421678303754562,\n",
    "    #         \"top-1-acc\": 0.8813,\n",
    "    #     },\n",
    "    # },\n",
    "    # \"our-alt-200\": {\n",
    "    #     \"linear_eval\": {\n",
    "    #         \"f1\": 0.4340359094457455,\n",
    "    #         \"precision\": 0.6813725490196079,\n",
    "    #         \"accuracy\": 0.8861852433281004,\n",
    "    #         \"recall\": 0.31844215349369986,\n",
    "    #         \"auc\": 0.6473964451296041,\n",
    "    #         \"top-1-acc\": 0.8862,\n",
    "    #     },\n",
    "    #     \"fine_tuned\": {\n",
    "    #         \"f1\": 0.5910735826296742,\n",
    "    #         \"precision\": 0.6242038216560509,\n",
    "    #         \"accuracy\": 0.893563579277865,\n",
    "    #         \"recall\": 0.561282932416953,\n",
    "    #         \"auc\": 0.7538086483078035,\n",
    "    #         \"top-1-acc\": 0.8936,\n",
    "    #     },\n",
    "    # },\n",
    "    # \"our-improved-100\": {\n",
    "    #     \"linear_eval\": {\n",
    "    #         \"f1\": 0.37995149555375907,\n",
    "    #         \"precision\": 0.6456043956043956,\n",
    "    #         \"accuracy\": 0.8795918367346939,\n",
    "    #         \"recall\": 0.26918671248568155,\n",
    "    #         \"auc\": 0.622859683330343,\n",
    "    #         \"top-1-acc\": 0.8796,\n",
    "    #     },\n",
    "    # },\n",
    "    # \"our-improved-150\": {\n",
    "    #     \"linear_eval\": {\n",
    "    #         \"f1\": 0.37702265372168287,\n",
    "    #         \"precision\": 0.6418732782369146,\n",
    "    #         \"accuracy\": 0.8791208791208791,\n",
    "    #         \"recall\": 0.26689576174112256,\n",
    "    #         \"auc\": 0.6216232492533155,\n",
    "    #         \"top-1-acc\": 0.8791,\n",
    "    #     }\n",
    "    # },\n",
    "    \"SimCLR\": {\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.35876623376623373,\n",
    "            \"precision\": 0.6155988857938719,\n",
    "            \"accuracy\": 0.8759811616954474,\n",
    "            \"recall\": 0.2531500572737686,\n",
    "            \"auc\": 0.6140227273816542,\n",
    "            \"top-1-acc\": 0.8760,\n",
    "        },\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5490430622009569,\n",
    "            \"precision\": 0.574468085106383,\n",
    "            \"accuracy\": 0.8816326530612245,\n",
    "            \"recall\": 0.5257731958762887,\n",
    "            \"auc\": 0.7319606383238092,\n",
    "            \"top-1-acc\": 0.8816,\n",
    "        },\n",
    "    },\n",
    "    # \"our-improved-v3\": {\n",
    "    #     \"linear_eval\": {\n",
    "    #         \"f1\": 0.326530612244898,\n",
    "    #         \"precision\": 0.6336633663366337,\n",
    "    #         \"accuracy\": 0.8756671899529043,\n",
    "    #         \"recall\": 0.21993127147766323,\n",
    "    #         \"auc\": 0.5998692195117987,\n",
    "    #         \"top-1-acc\": 0.8757,\n",
    "    #     },\n",
    "    #     \"fine_tuned\": {\n",
    "    #         \"f1\": 0.5682382133995036,\n",
    "    #         \"precision\": 0.6197564276048715,\n",
    "    #         \"accuracy\": 0.8907378335949765,\n",
    "    #         \"recall\": 0.5246277205040092,\n",
    "    #         \"auc\": 0.736754464217804,\n",
    "    #         \"top-1-acc\": 0.8907,\n",
    "    #     },\n",
    "    # },\n",
    "    \"SwAV\": {\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.32680851063829786,\n",
    "            \"precision\": 0.6357615894039735,\n",
    "            \"accuracy\": 0.8758241758241758,\n",
    "            \"recall\": 0.21993127147766323,\n",
    "            \"auc\": 0.5999601782165468,\n",
    "            \"top-1-acc\": 0.8758,\n",
    "        },\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5430140329469189,\n",
    "            \"precision\": 0.5809399477806788,\n",
    "            \"accuracy\": 0.8824175824175824,\n",
    "            \"recall\": 0.5097365406643757,\n",
    "            \"auc\": 0.7256705261080656,\n",
    "            \"top-1-acc\": 0.8824,\n",
    "        },\n",
    "    },\n",
    "    \"Our\": {  # our-improved-v4\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.4123222748815166,\n",
    "            \"precision\": 0.6641221374045801,\n",
    "            \"accuracy\": 0.8832025117739404,\n",
    "            \"recall\": 0.29896907216494845,\n",
    "            \"auc\": 0.6374779870557323,\n",
    "            \"top-1-acc\": 0.8832,\n",
    "        },\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5726817042606517,\n",
    "            \"precision\": 0.632088520055325,\n",
    "            \"accuracy\": 0.8929356357927787,\n",
    "            \"recall\": 0.5234822451317297,\n",
    "            \"auc\": 0.7375461071028849,\n",
    "            \"top-1-acc\": 0.8929,\n",
    "        },\n",
    "    },\n",
    "    \"Our-Without-AutoEncoder\": {\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.36154478225143794,\n",
    "            \"precision\": 0.6395348837209303,\n",
    "            \"accuracy\": 0.878021978021978,\n",
    "            \"recall\": 0.2520045819014891,\n",
    "            \"auc\": 0.6147234115619871,\n",
    "            \"top-1-acc\": 0.8780,\n",
    "        },\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5556962025316455,\n",
    "            \"precision\": 0.620933521923621,\n",
    "            \"accuracy\": 0.889795918367347,\n",
    "            \"recall\": 0.5028636884306987,\n",
    "            \"auc\": 0.7270549113428735,\n",
    "            \"top-1-acc\": 0.8898,\n",
    "        },\n",
    "    },\n",
    "    \"v8\": {\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.2739480752014324,\n",
    "            \"precision\": 0.6270491803278688,\n",
    "            \"accuracy\": 0.8726844583987441,\n",
    "            \"recall\": 0.17525773195876287,\n",
    "            \"auc\": 0.5793516238473094,\n",
    "            \"top-1-acc\": 0.8727,\n",
    "        },\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5356429047301798,\n",
    "            \"precision\": 0.6401273885350318,\n",
    "            \"accuracy\": 0.8905808477237048,\n",
    "            \"recall\": 0.46048109965635736,\n",
    "            \"auc\": 0.7096838825551206,\n",
    "            \"top-1-acc\": 0.8906,\n",
    "        },\n",
    "    },\n",
    "    # Waiting for the result without the autoencoder.\n",
    "    \"v11\": {\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.3555926544240401,\n",
    "            \"precision\": 0.6553846153846153,\n",
    "            \"accuracy\": 0.878806907378336,\n",
    "            \"recall\": 0.24398625429553264,\n",
    "            \"auc\": 0.6118057522159854,\n",
    "            \"top-1-acc\": 0.8788,\n",
    "        },\n",
    "        \"fine_tuned\": {},\n",
    "    },\n",
    "    \"v13\": {\n",
    "        \"linear_eval\": {\n",
    "            \"f1\": 0.38126009693053314,\n",
    "            \"precision\": 0.6465753424657534,\n",
    "            \"accuracy\": 0.8797488226059654,\n",
    "            \"recall\": 0.27033218785796104,\n",
    "            \"auc\": 0.6234324210164828,\n",
    "            \"top-1-acc\": 0.8797,\n",
    "        },\n",
    "        \"fine_tuned\": {\n",
    "            \"f1\": 0.5546731826511913,\n",
    "            \"precision\": 0.5942408376963351,\n",
    "            \"accuracy\": 0.8855572998430141,\n",
    "            \"recall\": 0.5200458190148912,\n",
    "            \"auc\": 0.7318257110355517,\n",
    "            \"top-1-acc\": 0.8856,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_eval_result_df = []\n",
    "for k, v in result_dict.items():\n",
    "    linear_eval_result_df.append(\n",
    "        {\n",
    "            \"algorithm\": k,\n",
    "            **v[\"linear_eval\"],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>top-1-acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supervised</td>\n",
       "      <td>0.345169</td>\n",
       "      <td>0.618343</td>\n",
       "      <td>0.875510</td>\n",
       "      <td>0.239404</td>\n",
       "      <td>0.607969</td>\n",
       "      <td>0.8755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SimSiam</td>\n",
       "      <td>0.098912</td>\n",
       "      <td>0.362319</td>\n",
       "      <td>0.856986</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.520633</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BYOL</td>\n",
       "      <td>0.348562</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.879121</td>\n",
       "      <td>0.235968</td>\n",
       "      <td>0.608615</td>\n",
       "      <td>0.8791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barlow Twins</td>\n",
       "      <td>0.265487</td>\n",
       "      <td>0.583658</td>\n",
       "      <td>0.869702</td>\n",
       "      <td>0.171821</td>\n",
       "      <td>0.576178</td>\n",
       "      <td>0.8697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MoCo</td>\n",
       "      <td>0.306897</td>\n",
       "      <td>0.620209</td>\n",
       "      <td>0.873783</td>\n",
       "      <td>0.203895</td>\n",
       "      <td>0.592033</td>\n",
       "      <td>0.8738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SimCLR</td>\n",
       "      <td>0.358766</td>\n",
       "      <td>0.615599</td>\n",
       "      <td>0.875981</td>\n",
       "      <td>0.253150</td>\n",
       "      <td>0.614023</td>\n",
       "      <td>0.8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SwAV</td>\n",
       "      <td>0.326809</td>\n",
       "      <td>0.635762</td>\n",
       "      <td>0.875824</td>\n",
       "      <td>0.219931</td>\n",
       "      <td>0.599960</td>\n",
       "      <td>0.8758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Our</td>\n",
       "      <td>0.412322</td>\n",
       "      <td>0.664122</td>\n",
       "      <td>0.883203</td>\n",
       "      <td>0.298969</td>\n",
       "      <td>0.637478</td>\n",
       "      <td>0.8832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Our-Without-AutoEncoder</td>\n",
       "      <td>0.361545</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.878022</td>\n",
       "      <td>0.252005</td>\n",
       "      <td>0.614723</td>\n",
       "      <td>0.8780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>v8</td>\n",
       "      <td>0.273948</td>\n",
       "      <td>0.627049</td>\n",
       "      <td>0.872684</td>\n",
       "      <td>0.175258</td>\n",
       "      <td>0.579352</td>\n",
       "      <td>0.8727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>v11</td>\n",
       "      <td>0.355593</td>\n",
       "      <td>0.655385</td>\n",
       "      <td>0.878807</td>\n",
       "      <td>0.243986</td>\n",
       "      <td>0.611806</td>\n",
       "      <td>0.8788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>v13</td>\n",
       "      <td>0.381260</td>\n",
       "      <td>0.646575</td>\n",
       "      <td>0.879749</td>\n",
       "      <td>0.270332</td>\n",
       "      <td>0.623432</td>\n",
       "      <td>0.8797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  algorithm        f1  precision  accuracy    recall  \\\n",
       "0                Supervised  0.345169   0.618343  0.875510  0.239404   \n",
       "1                   SimSiam  0.098912   0.362319  0.856986  0.057274   \n",
       "2                      BYOL  0.348562   0.666667  0.879121  0.235968   \n",
       "3              Barlow Twins  0.265487   0.583658  0.869702  0.171821   \n",
       "4                      MoCo  0.306897   0.620209  0.873783  0.203895   \n",
       "5                    SimCLR  0.358766   0.615599  0.875981  0.253150   \n",
       "6                      SwAV  0.326809   0.635762  0.875824  0.219931   \n",
       "7                       Our  0.412322   0.664122  0.883203  0.298969   \n",
       "8   Our-Without-AutoEncoder  0.361545   0.639535  0.878022  0.252005   \n",
       "9                        v8  0.273948   0.627049  0.872684  0.175258   \n",
       "10                      v11  0.355593   0.655385  0.878807  0.243986   \n",
       "11                      v13  0.381260   0.646575  0.879749  0.270332   \n",
       "\n",
       "         auc  top-1-acc  \n",
       "0   0.607969     0.8755  \n",
       "1   0.520633     0.8570  \n",
       "2   0.608615     0.8791  \n",
       "3   0.576178     0.8697  \n",
       "4   0.592033     0.8738  \n",
       "5   0.614023     0.8760  \n",
       "6   0.599960     0.8758  \n",
       "7   0.637478     0.8832  \n",
       "8   0.614723     0.8780  \n",
       "9   0.579352     0.8727  \n",
       "10  0.611806     0.8788  \n",
       "11  0.623432     0.8797  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_eval_result_df = pd.DataFrame(linear_eval_result_df)\n",
    "linear_eval_result_df.to_csv(\"[chexpert] linear_eval.csv\")\n",
    "linear_eval_result_df\n",
    "# from the result, then we know our-alt may be the best algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_result_df = []\n",
    "for k, v in result_dict.items():\n",
    "    fine_tuned_result_df.append(\n",
    "        {\n",
    "            \"algorithm\": k,\n",
    "            **v[\"fine_tuned\"],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>top-1-acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supervised</td>\n",
       "      <td>0.558401</td>\n",
       "      <td>0.614011</td>\n",
       "      <td>0.889011</td>\n",
       "      <td>0.512027</td>\n",
       "      <td>0.730454</td>\n",
       "      <td>0.8890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SimSiam</td>\n",
       "      <td>0.545566</td>\n",
       "      <td>0.585302</td>\n",
       "      <td>0.883359</td>\n",
       "      <td>0.510882</td>\n",
       "      <td>0.726698</td>\n",
       "      <td>0.8834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BYOL</td>\n",
       "      <td>0.563046</td>\n",
       "      <td>0.618656</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>0.516609</td>\n",
       "      <td>0.733018</td>\n",
       "      <td>0.8901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barlow Twins</td>\n",
       "      <td>0.563190</td>\n",
       "      <td>0.606341</td>\n",
       "      <td>0.888226</td>\n",
       "      <td>0.525773</td>\n",
       "      <td>0.735781</td>\n",
       "      <td>0.8882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MoCo</td>\n",
       "      <td>0.562918</td>\n",
       "      <td>0.599741</td>\n",
       "      <td>0.887127</td>\n",
       "      <td>0.530355</td>\n",
       "      <td>0.737071</td>\n",
       "      <td>0.8871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SimCLR</td>\n",
       "      <td>0.549043</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.881633</td>\n",
       "      <td>0.525773</td>\n",
       "      <td>0.731961</td>\n",
       "      <td>0.8816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SwAV</td>\n",
       "      <td>0.543014</td>\n",
       "      <td>0.580940</td>\n",
       "      <td>0.882418</td>\n",
       "      <td>0.509737</td>\n",
       "      <td>0.725671</td>\n",
       "      <td>0.8824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Our</td>\n",
       "      <td>0.572682</td>\n",
       "      <td>0.632089</td>\n",
       "      <td>0.892936</td>\n",
       "      <td>0.523482</td>\n",
       "      <td>0.737546</td>\n",
       "      <td>0.8929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Our-Without-AutoEncoder</td>\n",
       "      <td>0.555696</td>\n",
       "      <td>0.620934</td>\n",
       "      <td>0.889796</td>\n",
       "      <td>0.502864</td>\n",
       "      <td>0.727055</td>\n",
       "      <td>0.8898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>v8</td>\n",
       "      <td>0.535643</td>\n",
       "      <td>0.640127</td>\n",
       "      <td>0.890581</td>\n",
       "      <td>0.460481</td>\n",
       "      <td>0.709684</td>\n",
       "      <td>0.8906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>v11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>v13</td>\n",
       "      <td>0.554673</td>\n",
       "      <td>0.594241</td>\n",
       "      <td>0.885557</td>\n",
       "      <td>0.520046</td>\n",
       "      <td>0.731826</td>\n",
       "      <td>0.8856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  algorithm        f1  precision  accuracy    recall  \\\n",
       "0                Supervised  0.558401   0.614011  0.889011  0.512027   \n",
       "1                   SimSiam  0.545566   0.585302  0.883359  0.510882   \n",
       "2                      BYOL  0.563046   0.618656  0.890110  0.516609   \n",
       "3              Barlow Twins  0.563190   0.606341  0.888226  0.525773   \n",
       "4                      MoCo  0.562918   0.599741  0.887127  0.530355   \n",
       "5                    SimCLR  0.549043   0.574468  0.881633  0.525773   \n",
       "6                      SwAV  0.543014   0.580940  0.882418  0.509737   \n",
       "7                       Our  0.572682   0.632089  0.892936  0.523482   \n",
       "8   Our-Without-AutoEncoder  0.555696   0.620934  0.889796  0.502864   \n",
       "9                        v8  0.535643   0.640127  0.890581  0.460481   \n",
       "10                      v11       NaN        NaN       NaN       NaN   \n",
       "11                      v13  0.554673   0.594241  0.885557  0.520046   \n",
       "\n",
       "         auc  top-1-acc  \n",
       "0   0.730454     0.8890  \n",
       "1   0.726698     0.8834  \n",
       "2   0.733018     0.8901  \n",
       "3   0.735781     0.8882  \n",
       "4   0.737071     0.8871  \n",
       "5   0.731961     0.8816  \n",
       "6   0.725671     0.8824  \n",
       "7   0.737546     0.8929  \n",
       "8   0.727055     0.8898  \n",
       "9   0.709684     0.8906  \n",
       "10       NaN        NaN  \n",
       "11  0.731826     0.8856  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuned_result_df = pd.DataFrame(fine_tuned_result_df)\n",
    "fine_tuned_result_df.to_csv(\"[chexpert] fine_tuned.csv\")\n",
    "fine_tuned_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_result_dict = {\n",
    "    \"Supervised\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"map\": 0.0726,\n",
    "            \"map_50\": 0.1697,\n",
    "            \"map_75\": 0.0534,\n",
    "            \"map_small\": 0.0102,\n",
    "            \"map_medium\": 0.0827,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1376,\n",
    "            \"mar_10\": 0.1666,\n",
    "            \"mar_100\": 0.1666,\n",
    "            \"mar_small\": 0.0484,\n",
    "            \"mar_medium\": 0.1921,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"map\": 0.0643,\n",
    "            \"map_50\": 0.1727,\n",
    "            \"map_75\": 0.0287,\n",
    "            \"map_small\": 0.0080,\n",
    "            \"map_medium\": 0.0748,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1310,\n",
    "            \"mar_10\": 0.2295,\n",
    "            \"mar_100\": 0.2452,\n",
    "            \"mar_small\": 0.1247,\n",
    "            \"mar_medium\": 0.2898,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "    },\n",
    "    \"SimSiam\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"map\": 0.0795,\n",
    "            \"map_50\": 0.1969,\n",
    "            \"map_75\": 0.0479,\n",
    "            \"map_small\": 0.0090,\n",
    "            \"map_medium\": 0.0942,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1418,\n",
    "            \"mar_10\": 0.1907,\n",
    "            \"mar_100\": 0.1907,\n",
    "            \"mar_small\": 0.0712,\n",
    "            \"mar_medium\": 0.2282,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"map\": 0.0608,\n",
    "            \"map_50\": 0.1684,\n",
    "            \"map_75\": 0.0267,\n",
    "            \"map_small\": 0.0118,\n",
    "            \"map_medium\": 0.0726,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1385,\n",
    "            \"mar_10\": 0.2781,\n",
    "            \"mar_100\": 0.2962,\n",
    "            \"mar_small\": 0.1648,\n",
    "            \"mar_medium\": 0.3503,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "    },\n",
    "    \"BYOL\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"map\": 0.0675,\n",
    "            \"map_50\": 0.1669,\n",
    "            \"map_75\": 0.0434,\n",
    "            \"map_small\": 0.0065,\n",
    "            \"map_medium\": 0.0837,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1388,\n",
    "            \"mar_10\": 0.1765,\n",
    "            \"mar_100\": 0.1765,\n",
    "            \"mar_small\": 0.0519,\n",
    "            \"mar_medium\": 0.2109,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"map\": 0.0332,\n",
    "            \"map_50\": 0.0970,\n",
    "            \"map_75\": 0.0146,\n",
    "            \"map_small\": 0.0074,\n",
    "            \"map_medium\": 0.0461,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1163,\n",
    "            \"mar_10\": 0.2275,\n",
    "            \"mar_100\": 0.2431,\n",
    "            \"mar_small\": 0.1584,\n",
    "            \"mar_medium\": 0.2749,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "    },\n",
    "    \"Barlow Twins\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"map\": 0.0802,\n",
    "            \"map_50\": 0.1907,\n",
    "            \"map_75\": 0.0565,\n",
    "            \"map_small\": 0.0119,\n",
    "            \"map_medium\": 0.0949,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1510,\n",
    "            \"mar_10\": 0.1862,\n",
    "            \"mar_100\": 0.1862,\n",
    "            \"mar_small\": 0.0579,\n",
    "            \"mar_medium\": 0.2223,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"map\": 0.0700,\n",
    "            \"map_50\": 0.1781,\n",
    "            \"map_75\": 0.0365,\n",
    "            \"map_small\": 0.0143,\n",
    "            \"map_medium\": 0.0812,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1443,\n",
    "            \"mar_10\": 0.2801,\n",
    "            \"mar_100\": 0.2896,\n",
    "            \"mar_small\": 0.1569,\n",
    "            \"mar_medium\": 0.3454,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "    },\n",
    "    \"MoCo\": {\n",
    "        \"fine_tuned\": {\n",
    "            \"map\": 0.0772,\n",
    "            \"map_50\": 0.1861,\n",
    "            \"map_75\": 0.0533,\n",
    "            \"map_small\": 0.0089,\n",
    "            \"map_medium\": 0.0908,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1483,\n",
    "            \"mar_10\": 0.1827,\n",
    "            \"mar_100\": 0.1827,\n",
    "            \"mar_small\": 0.0577,\n",
    "            \"mar_medium\": 0.2156,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "        \"linear_eval\": {\n",
    "            \"map\": 0.0725,\n",
    "            \"map_50\": 0.1938,\n",
    "            \"map_75\": 0.0361,\n",
    "            \"map_small\": 0.0145,\n",
    "            \"map_medium\": 0.0842,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1550,\n",
    "            \"mar_10\": 0.2829,\n",
    "            \"mar_100\": 0.2959,\n",
    "            \"mar_small\": 0.1699,\n",
    "            \"mar_medium\": 0.3458,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "    },\n",
    "    \"SimCLR\": {\n",
    "        \"linear_eval\": {\n",
    "            \"map\": 0.0734,\n",
    "            \"map_50\": 0.1929,\n",
    "            \"map_75\": 0.0528,\n",
    "            \"map_small\": 0.0127,\n",
    "            \"map_medium\": 0.0849,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1460,\n",
    "            \"mar_10\": 0.2752,\n",
    "            \"mar_100\": 0.2889,\n",
    "            \"mar_small\": 0.1712,\n",
    "            \"mar_medium\": 0.3332,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "        \"fine_tuned\": {\n",
    "            \"map\": 0.0706,\n",
    "            \"map_50\": 0.1780,\n",
    "            \"map_75\": 0.0387,\n",
    "            \"map_small\": 0.0095,\n",
    "            \"map_medium\": 0.0895,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1449,\n",
    "            \"mar_10\": 0.1789,\n",
    "            \"mar_100\": 0.1789,\n",
    "            \"mar_small\": 0.0541,\n",
    "            \"mar_medium\": 0.2167,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "    },\n",
    "    \"SwAV\": {\n",
    "        \"linear_eval\": {\n",
    "            \"map\": 0.0710,\n",
    "            \"map_50\": 0.1891,\n",
    "            \"map_75\": 0.0451,\n",
    "            \"map_small\": 0.0123,\n",
    "            \"map_medium\": 0.0832,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1404,\n",
    "            \"mar_10\": 0.2715,\n",
    "            \"mar_100\": 0.2865,\n",
    "            \"mar_small\": 0.1648,\n",
    "            \"mar_medium\": 0.3383,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "        \"fine_tuned\": {\n",
    "            \"map\": 0.0723,\n",
    "            \"map_50\": 0.1818,\n",
    "            \"map_75\": 0.0455,\n",
    "            \"map_small\": 0.0056,\n",
    "            \"map_medium\": 0.0894,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1471,\n",
    "            \"mar_10\": 0.1888,\n",
    "            \"mar_100\": 0.1888,\n",
    "            \"mar_small\": 0.0484,\n",
    "            \"mar_medium\": 0.2333,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "    },\n",
    "    \"Our\": {  # our-improved-v4\n",
    "        \"linear_eval\": {\n",
    "            \"map\": 0.0674,\n",
    "            \"map_50\": 0.1801,\n",
    "            \"map_75\": 0.0379,\n",
    "            \"map_small\": 0.0132,\n",
    "            \"map_medium\": 0.0782,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1347,\n",
    "            \"mar_10\": 0.2486,\n",
    "            \"mar_100\": 0.2617,\n",
    "            \"mar_small\": 0.1448,\n",
    "            \"mar_medium\": 0.3071,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "        \"fine_tuned\": {\n",
    "            \"map\": 0.0726,\n",
    "            \"map_50\": 0.1733,\n",
    "            \"map_75\": 0.0528,\n",
    "            \"map_small\": 0.0056,\n",
    "            \"map_medium\": 0.0883,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1522,\n",
    "            \"mar_10\": 0.1802,\n",
    "            \"mar_100\": 0.1802,\n",
    "            \"mar_small\": 0.0509,\n",
    "            \"mar_medium\": 0.2137,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "    },\n",
    "    \"Our-Without-AutoEncoder\": {\n",
    "        \"linear_eval\": {\n",
    "            \"map\": 0.0737,\n",
    "            \"map_50\": 0.1939,\n",
    "            \"map_75\": 0.0439,\n",
    "            \"map_small\": 0.0128,\n",
    "            \"map_medium\": 0.0857,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1465,\n",
    "            \"mar_10\": 0.2635,\n",
    "            \"mar_100\": 0.2762,\n",
    "            \"mar_small\": 0.1478,\n",
    "            \"mar_medium\": 0.3253,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "        \"fine_tuned\": {\n",
    "            \"map\": 0.0673,\n",
    "            \"map_50\": 0.1620,\n",
    "            \"map_75\": 0.0521,\n",
    "            \"map_small\": 0.0069,\n",
    "            \"map_medium\": 0.0774,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1383,\n",
    "            \"mar_10\": 0.1693,\n",
    "            \"mar_100\": 0.1693,\n",
    "            \"mar_small\": 0.0507,\n",
    "            \"mar_medium\": 0.1973,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "    },\n",
    "    \"v8\": {\n",
    "        \"linear_eval\": {\n",
    "            \"map\": 0.0792,\n",
    "            \"map_50\": 0.2015,\n",
    "            \"map_75\": 0.0390,\n",
    "            \"map_small\": 0.0169,\n",
    "            \"map_medium\": 0.0916,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1487,\n",
    "            \"mar_10\": 0.2688,\n",
    "            \"mar_100\": 0.2798,\n",
    "            \"mar_small\": 0.1488,\n",
    "            \"mar_medium\": 0.3296,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "        \"fine_tuned\": {\n",
    "            \"map\": 0.0675,\n",
    "            \"map_50\": 0.1491,\n",
    "            \"map_75\": 0.0498,\n",
    "            \"map_small\": 0.0063,\n",
    "            \"map_medium\": 0.0789,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1394,\n",
    "            \"mar_10\": 0.1673,\n",
    "            \"mar_100\": 0.1673,\n",
    "            \"mar_small\": 0.0527,\n",
    "            \"mar_medium\": 0.1962,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "    },\n",
    "    \"v11\": {\n",
    "        \"linear_eval\": {\n",
    "            \"map\": 0.0683,\n",
    "            \"map_50\": 0.1808,\n",
    "            \"map_75\": 0.0370,\n",
    "            \"map_small\": 0.0102,\n",
    "            \"map_medium\": 0.0797,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1400,\n",
    "            \"mar_10\": 0.2539,\n",
    "            \"mar_100\": 0.2635,\n",
    "            \"mar_small\": 0.1459,\n",
    "            \"mar_medium\": 0.3066,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "        \"fine_tuned\": {\n",
    "            \"map\": 0.0706,\n",
    "            \"map_50\": 0.1660,\n",
    "            \"map_75\": 0.0579,\n",
    "            \"map_small\": 0.0070,\n",
    "            \"map_medium\": 0.0807,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1400,\n",
    "            \"mar_10\": 0.1695,\n",
    "            \"mar_100\": 0.1695,\n",
    "            \"mar_small\": 0.0579,\n",
    "            \"mar_medium\": 0.1943,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        },\n",
    "    },\n",
    "    \"v13\": {\n",
    "        \"linear_eval\": {\n",
    "            \"map\": 0.0604,\n",
    "            \"map_50\": 0.1848,\n",
    "            \"map_75\": 0.0252,\n",
    "            \"map_small\": 0.0139,\n",
    "            \"map_medium\": 0.0712,\n",
    "            \"map_large\": -1.0,\n",
    "            \"mar_1\": 0.1312,\n",
    "            \"mar_10\": 0.2621,\n",
    "            \"mar_100\": 0.2732,\n",
    "            \"mar_small\": 0.1623,\n",
    "            \"mar_medium\": 0.3184,\n",
    "            \"mar_large\": -1.0,\n",
    "            \"map_per_class\": -1.0,\n",
    "            \"mar_100_per_class\": -1.0,\n",
    "        }\n",
    "    },\n",
    "    # Waiting for the result without the autoencoder.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_eval_detection_result_df = []\n",
    "for k, v in detection_result_dict.items():\n",
    "    linear_eval_detection_result_df.append(\n",
    "        {\n",
    "            \"algorithm\": k,\n",
    "            **v[\"linear_eval\"],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>map</th>\n",
       "      <th>map_50</th>\n",
       "      <th>map_75</th>\n",
       "      <th>map_small</th>\n",
       "      <th>map_medium</th>\n",
       "      <th>map_large</th>\n",
       "      <th>mar_1</th>\n",
       "      <th>mar_10</th>\n",
       "      <th>mar_100</th>\n",
       "      <th>mar_small</th>\n",
       "      <th>mar_medium</th>\n",
       "      <th>mar_large</th>\n",
       "      <th>map_per_class</th>\n",
       "      <th>mar_100_per_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supervised</td>\n",
       "      <td>0.0643</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.2295</td>\n",
       "      <td>0.2452</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>0.2898</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SimSiam</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.1684</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.2781</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.3503</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BYOL</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1163</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.2749</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barlow Twins</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.1781</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.2801</td>\n",
       "      <td>0.2896</td>\n",
       "      <td>0.1569</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MoCo</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.1938</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.2829</td>\n",
       "      <td>0.2959</td>\n",
       "      <td>0.1699</td>\n",
       "      <td>0.3458</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SimCLR</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.2752</td>\n",
       "      <td>0.2889</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.3332</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SwAV</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>0.1891</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1404</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>0.2865</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.3383</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Our</td>\n",
       "      <td>0.0674</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.0379</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.2486</td>\n",
       "      <td>0.2617</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.3071</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Our-Without-AutoEncoder</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.1939</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2635</td>\n",
       "      <td>0.2762</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.3253</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>v8</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>0.2015</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.3296</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>v11</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>0.1808</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.2539</td>\n",
       "      <td>0.2635</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.3066</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>v13</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.1848</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.2621</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.1623</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  algorithm     map  map_50  map_75  map_small  map_medium  \\\n",
       "0                Supervised  0.0643  0.1727  0.0287     0.0080      0.0748   \n",
       "1                   SimSiam  0.0608  0.1684  0.0267     0.0118      0.0726   \n",
       "2                      BYOL  0.0332  0.0970  0.0146     0.0074      0.0461   \n",
       "3              Barlow Twins  0.0700  0.1781  0.0365     0.0143      0.0812   \n",
       "4                      MoCo  0.0725  0.1938  0.0361     0.0145      0.0842   \n",
       "5                    SimCLR  0.0734  0.1929  0.0528     0.0127      0.0849   \n",
       "6                      SwAV  0.0710  0.1891  0.0451     0.0123      0.0832   \n",
       "7                       Our  0.0674  0.1801  0.0379     0.0132      0.0782   \n",
       "8   Our-Without-AutoEncoder  0.0737  0.1939  0.0439     0.0128      0.0857   \n",
       "9                        v8  0.0792  0.2015  0.0390     0.0169      0.0916   \n",
       "10                      v11  0.0683  0.1808  0.0370     0.0102      0.0797   \n",
       "11                      v13  0.0604  0.1848  0.0252     0.0139      0.0712   \n",
       "\n",
       "    map_large   mar_1  mar_10  mar_100  mar_small  mar_medium  mar_large  \\\n",
       "0        -1.0  0.1310  0.2295   0.2452     0.1247      0.2898       -1.0   \n",
       "1        -1.0  0.1385  0.2781   0.2962     0.1648      0.3503       -1.0   \n",
       "2        -1.0  0.1163  0.2275   0.2431     0.1584      0.2749       -1.0   \n",
       "3        -1.0  0.1443  0.2801   0.2896     0.1569      0.3454       -1.0   \n",
       "4        -1.0  0.1550  0.2829   0.2959     0.1699      0.3458       -1.0   \n",
       "5        -1.0  0.1460  0.2752   0.2889     0.1712      0.3332       -1.0   \n",
       "6        -1.0  0.1404  0.2715   0.2865     0.1648      0.3383       -1.0   \n",
       "7        -1.0  0.1347  0.2486   0.2617     0.1448      0.3071       -1.0   \n",
       "8        -1.0  0.1465  0.2635   0.2762     0.1478      0.3253       -1.0   \n",
       "9        -1.0  0.1487  0.2688   0.2798     0.1488      0.3296       -1.0   \n",
       "10       -1.0  0.1400  0.2539   0.2635     0.1459      0.3066       -1.0   \n",
       "11       -1.0  0.1312  0.2621   0.2732     0.1623      0.3184       -1.0   \n",
       "\n",
       "    map_per_class  mar_100_per_class  \n",
       "0            -1.0               -1.0  \n",
       "1            -1.0               -1.0  \n",
       "2            -1.0               -1.0  \n",
       "3            -1.0               -1.0  \n",
       "4            -1.0               -1.0  \n",
       "5            -1.0               -1.0  \n",
       "6            -1.0               -1.0  \n",
       "7            -1.0               -1.0  \n",
       "8            -1.0               -1.0  \n",
       "9            -1.0               -1.0  \n",
       "10           -1.0               -1.0  \n",
       "11           -1.0               -1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_eval_detection_result_df = pd.DataFrame(linear_eval_detection_result_df)\n",
    "linear_eval_detection_result_df.to_csv(\"[detection] linear_eval.csv\")\n",
    "linear_eval_detection_result_df\n",
    "# from the result, then we know our-alt may be the best algorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fine_tuned'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m fine_tuned_detection_result_df \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m detection_result_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      3\u001b[0m     fine_tuned_detection_result_df\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m      4\u001b[0m         {\n\u001b[0;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m\"\u001b[39m: k,\n\u001b[1;32m----> 6\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfine_tuned\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[0;32m      7\u001b[0m         }\n\u001b[0;32m      8\u001b[0m     )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'fine_tuned'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fine_tuned_detection_result_df = []\n",
    "for k, v in detection_result_dict.items():\n",
    "    fine_tuned_detection_result_df.append(\n",
    "        {\n",
    "            \"algorithm\": k,\n",
    "            **v[\"fine_tuned\"],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>map</th>\n",
       "      <th>map_50</th>\n",
       "      <th>map_75</th>\n",
       "      <th>map_small</th>\n",
       "      <th>map_medium</th>\n",
       "      <th>map_large</th>\n",
       "      <th>mar_1</th>\n",
       "      <th>mar_10</th>\n",
       "      <th>mar_100</th>\n",
       "      <th>mar_small</th>\n",
       "      <th>mar_medium</th>\n",
       "      <th>mar_large</th>\n",
       "      <th>map_per_class</th>\n",
       "      <th>mar_100_per_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supervised</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0827</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.1921</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SimSiam</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.1907</td>\n",
       "      <td>0.1907</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BYOL</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0837</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.2109</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barlow Twins</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.1907</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>0.2223</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MoCo</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.1827</td>\n",
       "      <td>0.1827</td>\n",
       "      <td>0.0577</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SimCLR</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1449</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SwAV</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Our</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Our-Without-AutoEncoder</td>\n",
       "      <td>0.0673</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.1693</td>\n",
       "      <td>0.1693</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>v8</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>v11</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0807</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  algorithm     map  map_50  map_75  map_small  map_medium  \\\n",
       "0                Supervised  0.0726  0.1697  0.0534     0.0102      0.0827   \n",
       "1                   SimSiam  0.0795  0.1969  0.0479     0.0090      0.0942   \n",
       "2                      BYOL  0.0675  0.1669  0.0434     0.0065      0.0837   \n",
       "3              Barlow Twins  0.0802  0.1907  0.0565     0.0119      0.0949   \n",
       "4                      MoCo  0.0772  0.1861  0.0533     0.0089      0.0908   \n",
       "5                    SimCLR  0.0706  0.1780  0.0387     0.0095      0.0895   \n",
       "6                      SwAV  0.0723  0.1818  0.0455     0.0056      0.0894   \n",
       "7                       Our  0.0726  0.1733  0.0528     0.0056      0.0883   \n",
       "8   Our-Without-AutoEncoder  0.0673  0.1620  0.0521     0.0069      0.0774   \n",
       "9                        v8  0.0675  0.1491  0.0498     0.0063      0.0789   \n",
       "10                      v11  0.0706  0.1660  0.0579     0.0070      0.0807   \n",
       "\n",
       "    map_large   mar_1  mar_10  mar_100  mar_small  mar_medium  mar_large  \\\n",
       "0        -1.0  0.1376  0.1666   0.1666     0.0484      0.1921       -1.0   \n",
       "1        -1.0  0.1418  0.1907   0.1907     0.0712      0.2282       -1.0   \n",
       "2        -1.0  0.1388  0.1765   0.1765     0.0519      0.2109       -1.0   \n",
       "3        -1.0  0.1510  0.1862   0.1862     0.0579      0.2223       -1.0   \n",
       "4        -1.0  0.1483  0.1827   0.1827     0.0577      0.2156       -1.0   \n",
       "5        -1.0  0.1449  0.1789   0.1789     0.0541      0.2167       -1.0   \n",
       "6        -1.0  0.1471  0.1888   0.1888     0.0484      0.2333       -1.0   \n",
       "7        -1.0  0.1522  0.1802   0.1802     0.0509      0.2137       -1.0   \n",
       "8        -1.0  0.1383  0.1693   0.1693     0.0507      0.1973       -1.0   \n",
       "9        -1.0  0.1394  0.1673   0.1673     0.0527      0.1962       -1.0   \n",
       "10       -1.0  0.1400  0.1695   0.1695     0.0579      0.1943       -1.0   \n",
       "\n",
       "    map_per_class  mar_100_per_class  \n",
       "0            -1.0               -1.0  \n",
       "1            -1.0               -1.0  \n",
       "2            -1.0               -1.0  \n",
       "3            -1.0               -1.0  \n",
       "4            -1.0               -1.0  \n",
       "5            -1.0               -1.0  \n",
       "6            -1.0               -1.0  \n",
       "7            -1.0               -1.0  \n",
       "8            -1.0               -1.0  \n",
       "9            -1.0               -1.0  \n",
       "10           -1.0               -1.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuned_detection_result_df = pd.DataFrame(fine_tuned_detection_result_df)\n",
    "fine_tuned_detection_result_df.to_csv(\"[detection] fine_tuned.csv\")\n",
    "fine_tuned_detection_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>map_50</th>\n",
       "      <th>mar_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supervised</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>0.1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SimSiam</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.1907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BYOL</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.1765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barlow Twins</td>\n",
       "      <td>0.1907</td>\n",
       "      <td>0.1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MoCo</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.1827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SimCLR</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>0.1789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SwAV</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Our</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Our-Without-AutoEncoder</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>v8</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.1673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>v11</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.1695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  algorithm  map_50  mar_100\n",
       "0                Supervised  0.1697   0.1666\n",
       "1                   SimSiam  0.1969   0.1907\n",
       "2                      BYOL  0.1669   0.1765\n",
       "3              Barlow Twins  0.1907   0.1862\n",
       "4                      MoCo  0.1861   0.1827\n",
       "5                    SimCLR  0.1780   0.1789\n",
       "6                      SwAV  0.1818   0.1888\n",
       "7                       Our  0.1733   0.1802\n",
       "8   Our-Without-AutoEncoder  0.1620   0.1693\n",
       "9                        v8  0.1491   0.1673\n",
       "10                      v11  0.1660   0.1695"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuned_detection_result_df[['algorithm','map_50', 'mar_100']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mike8\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\_contextlib.py:125: UserWarning: Decorating classes is deprecated and will be disabled in future versions. You should only decorate functions or methods. To preserve the current behavior of class decoration, you can directly decorate the `__init__` method and nothing else.\n",
      "  warnings.warn(\"Decorating classes is deprecated and will be disabled in \"\n"
     ]
    }
   ],
   "source": [
    "from ds.physio.general import PhysioNetClinicalDataset\n",
    "\n",
    "\n",
    "d = PhysioNetClinicalDataset(split_str=\"train\", image_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "4        0\n",
       "5        0\n",
       "        ..\n",
       "67151    1\n",
       "67152    0\n",
       "67153    0\n",
       "67154    0\n",
       "67155    0\n",
       "Name: gender, Length: 60238, dtype: int32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.df['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"spreadsheets\", \"physio_clinical.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n"
     ]
    }
   ],
   "source": [
    "for s in pd.get_dummies(df['gender'], drop_first=True):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_deviation_edge(x, deviation=1):\n",
    "    return deviation if x else (-1)* deviation\n",
    "\n",
    "feature_dummies = pd.get_dummies(df['gender'], prefix=\"gender\", drop_first=True)\n",
    "for col in feature_dummies.columns:\n",
    "    feature_dummies[col] = feature_dummies[col].apply(lambda x : map_to_deviation_edge(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender_M\n",
       "-1          34119\n",
       " 1          33037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dummies.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss.moco import MoCoLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MoCoLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.3736, device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "B = 64 \n",
    "D = 512\n",
    "a = torch.randn(B, D).cuda()\n",
    "loss(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3101, -0.3542,  0.1785,  ..., -1.2374,  1.3755,  1.9477],\n",
       "        [ 0.0128, -0.1464, -0.9949,  ..., -0.3409, -0.5554, -0.9958],\n",
       "        [ 1.0968, -0.9951, -0.2476,  ..., -0.0818, -0.5277, -0.4924],\n",
       "        ...,\n",
       "        [ 1.6105,  0.6961,  0.3068,  ...,  0.0118, -1.3532, -0.1098],\n",
       "        [ 0.5074,  2.7076, -0.2541,  ...,  0.8048, -0.6076,  1.5301],\n",
       "        [ 0.0852,  0.0620, -1.1885,  ...,  0.3724,  0.9103, -0.3268]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = nn.functional.normalize(a, dim=1)\n",
    "k = nn.functional.normalize(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = q@k.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.arange(B).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, -0.0088,  0.0949,  ...,  0.0320,  0.1086, -0.0362],\n",
       "        [-0.0088,  1.0000,  0.0297,  ...,  0.0096, -0.0037, -0.0418],\n",
       "        [ 0.0949,  0.0297,  1.0000,  ..., -0.0160, -0.0215,  0.0258],\n",
       "        ...,\n",
       "        [ 0.0320,  0.0096, -0.0160,  ...,  1.0000,  0.0500,  0.0787],\n",
       "        [ 0.1086, -0.0037, -0.0215,  ...,  0.0500,  1.0000, -0.0049],\n",
       "        [-0.0362, -0.0418,  0.0258,  ...,  0.0787, -0.0049,  1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1868, device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.cross_entropy(logits,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss.simclr import SimCLRLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_loss = SimCLRLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0063, device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_loss(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(B, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7028)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.cross_entropy(b, torch.argmax(b, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(torch.argmax(b, dim=1).numpy(), torch.argmax(b, dim=1).float().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[2.19, 2.200004, 2.2]])\n",
    "nn.functional.cross_entropy(a, torch.tensor([1]))\n",
    "nn.functional.cross_entropy(logits[[0],:].cpu(), torch.tensor([0]))\n",
    "logits[[0],:].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0953)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1872)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00, -8.8168e-03,  9.4925e-02, -5.9399e-04,  1.1901e-01,\n",
       "         -1.0528e-01, -1.0938e-01,  8.7594e-02,  4.5190e-02,  1.0288e-03,\n",
       "         -5.9302e-02,  2.8093e-02, -2.1316e-02,  7.6999e-02,  4.7986e-02,\n",
       "         -5.2886e-02, -3.4156e-03, -2.0746e-02,  4.8854e-02, -3.3143e-02,\n",
       "          1.6035e-02, -1.0968e-02,  3.3107e-02,  4.6422e-03, -5.4882e-02,\n",
       "          2.7555e-02, -4.8285e-02,  1.3651e-03, -7.8240e-04, -2.5354e-02,\n",
       "         -2.0438e-02, -3.4583e-02,  5.1702e-02, -8.8318e-02, -8.1434e-03,\n",
       "          2.7903e-02,  4.7729e-03, -6.6267e-02,  1.4871e-02,  5.7052e-02,\n",
       "         -2.4402e-02,  6.8588e-03,  1.3027e-02, -1.9310e-02, -5.2211e-02,\n",
       "         -1.4357e-02, -3.7220e-02,  9.2580e-02, -9.0441e-02,  3.5643e-02,\n",
       "         -1.1189e-01,  1.8236e-02,  6.5407e-02,  9.9872e-02,  2.6284e-02,\n",
       "         -1.9818e-03,  6.4270e-02, -5.3434e-02, -5.7552e-02, -9.1647e-03,\n",
       "         -4.3196e-02,  3.1969e-02,  1.0862e-01, -3.6185e-02]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import datasets.paths as d_path\n",
    "import torchvision\n",
    "\n",
    "from engine.lesion_detection_detr import train_one_epoch, evaluate\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from config import ConfigArgs\n",
    "from utils.train import EarlyStopper, TrainingInfo, epoch_end_print, get_dataloaders, get_datasets\n",
    "from utils.plot import plot_losses\n",
    "from IPython.display import clear_output\n",
    "from datasets.reflacx.lesion_detection import REFLACXLesionDetectionDataset\n",
    "from engine.lesion_detection import check_best, end_train, load_backbone\n",
    "from models.detr.detr import build_detr\n",
    "\n",
    "from utils.train import set_weights_trainable\n",
    "import warnings\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n",
    "device = clean_memory_get_device()\n",
    "# device = torch.device(\"cpu\")\n",
    "reproducibility()\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.dataset import REFLACXLesionDetectionDatasetArgs\n",
    "from config.model import DETRArgs, FasterRCNNArgs\n",
    "from config.training import LesionDetectionArgs\n",
    "\n",
    "training_args = LesionDetectionArgs(\n",
    "    name=\"lesion_detection\",\n",
    "    batch_size=4,\n",
    "    early_stopping_patience = 10,\n",
    ")\n",
    "dataset_args = REFLACXLesionDetectionDatasetArgs(\n",
    "    image_size=128,\n",
    ")\n",
    "\n",
    "cl_model_name = \"MCL_resnet50_accuracy_0_1433_epoch48_10-08-2023 15-58-25\"\n",
    "\n",
    "configs = [\n",
    "    # ConfigArgs(\n",
    "    #     training=training_args,\n",
    "    #     dataset=dataset_args,\n",
    "    #     model=FasterRCNNArgs(\n",
    "    #         name=\"CL_NoFix\",\n",
    "    #         weights=\"cl\",\n",
    "    #         cl_model_name=cl_model_name,\n",
    "    #         trainable_backbone_layers=5,\n",
    "    #     )\n",
    "    # ),\n",
    "    # ConfigArgs(\n",
    "    #     training=training_args,\n",
    "    #     dataset=dataset_args,\n",
    "    #     model=FasterRCNNArgs(\n",
    "    #         name=\"CL_Fix5\",\n",
    "    #         weights=\"cl\",\n",
    "    #         cl_model_name=cl_model_name,\n",
    "    #         trainable_backbone_layers=0,\n",
    "    #     )\n",
    "    # ),\n",
    "    \n",
    "    ConfigArgs(\n",
    "        training=training_args,\n",
    "        dataset=dataset_args,\n",
    "        model=DETRArgs(\n",
    "            name=\"CL_Fix5Layers\",\n",
    "            weights=\"cl\",\n",
    "            cl_model_name=cl_model_name,\n",
    "            trainable_backbone_layers=0,\n",
    "        ),\n",
    "    ),\n",
    "\n",
    "    # ConfigArgs(\n",
    "    #     training=training_args,\n",
    "    #     dataset=dataset_args,\n",
    "    #     model=FasterRCNNArgs(\n",
    "    #         name=\"ImageNet_Fix5layers\",\n",
    "    #         weights=\"imagenet\",\n",
    "    #         trainable_backbone_layers=0,\n",
    "    #     )\n",
    "    # ),\n",
    "\n",
    "    # ConfigArgs(\n",
    "    #     training=training_args,\n",
    "    #     dataset=dataset_args,\n",
    "    #     model=FasterRCNNArgs(\n",
    "    #         name=\"CL_Fix2Layers\",\n",
    "    #         weights=\"cl\",\n",
    "    #         cl_model_name=cl_model_name,\n",
    "    #         trainable_backbone_layers=3,\n",
    "    #     )\n",
    "    # ),\n",
    "    # ConfigArgs(\n",
    "    #     training=training_args,\n",
    "    #     dataset=dataset_args,\n",
    "    #     model=FasterRCNNArgs(\n",
    "    #         name=\"ImageNet_Fix2Layers\",\n",
    "    #         weights=\"imagenet\",\n",
    "    #         trainable_backbone_layers=3,\n",
    "    #     )\n",
    "    # ),\n",
    "    # ConfigArgs(\n",
    "    #     training=training_args,\n",
    "    #     dataset=dataset_args,\n",
    "    #     model=FasterRCNNArgs(\n",
    "    #         name=\"random\",\n",
    "    #         weights=None,\n",
    "    #         trainable_backbone_layers=5,\n",
    "    #     )\n",
    "    # ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxes = box_xyxy_to_cxcywh(boxes) / self.image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200  # 200\n",
    "train_infos: list[TrainingInfo] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load this one into\n",
    "# backbone = load_backbone(config, device)\n",
    "# backbone.body\n",
    "# model.backbone[0].body = backbone.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config in configs:\n",
    "    device = clean_memory_get_device()\n",
    "    reproducibility()\n",
    "\n",
    "    train_info = TrainingInfo(config)\n",
    "\n",
    "    model, criterion, postprocessors = build_detr(\n",
    "        backbone=\"resnet18\",\n",
    "        train_backbone=\"true\",\n",
    "        hidden_dim=config.model.hidden_dim,\n",
    "        dilation=config.model.dilation,\n",
    "        position_embedding=config.model.position_embedding,\n",
    "        dropout=config.model.dropout,\n",
    "        nheads=config.model.nheads,\n",
    "        dim_feedforward=config.model.dim_feedforward,\n",
    "        enc_layers=config.model.enc_layers,\n",
    "        dec_layers=config.model.dec_layers,\n",
    "        pre_norm=config.model.pre_norm,\n",
    "        num_classes=len(config.dataset.label_cols),\n",
    "        num_queries=config.model.num_queries,\n",
    "        aux_loss=config.model.aux_loss,\n",
    "        set_cost_class=config.model.set_cost_class,\n",
    "        set_cost_bbox=config.model.set_cost_bbox,\n",
    "        set_cost_giou=config.model.set_cost_giou,\n",
    "        giou_loss_coef=config.model.giou_loss_coef,\n",
    "        bbox_loss_coef=config.model.bbox_loss_coef,\n",
    "        eos_coef=config.model.eos_coef,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # weights.\n",
    "    backbone = load_backbone(config, device)\n",
    "    model.backbone[0].body = backbone.body\n",
    "    # model.backbone = backbone\n",
    "    model.to(device)\n",
    "\n",
    "    dataset_args = {\n",
    "        \"df_path\": os.path.join(\"spreadsheets\", \"reflacx.csv\"),\n",
    "        \"mimic_eye_path\": d_path.MIMIC_EYE_PATH,\n",
    "        \"image_size\": config.dataset.image_size,\n",
    "        \"label_cols\": config.dataset.label_cols,\n",
    "        \"cxcywh\": True,\n",
    "    }\n",
    "\n",
    "    train_dataset, val_dataset, _ = get_datasets(\n",
    "        dataset_args=dataset_args,\n",
    "        dataset_class=REFLACXLesionDetectionDataset,\n",
    "    )\n",
    "\n",
    "    train_dataloader, val_dataloader = get_dataloaders(\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        batch_size=config.training.batch_size,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        params=[p for p in model.parameters() if p.requires_grad],\n",
    "        lr=config.training.learning_rate,\n",
    "        weight_decay=config.training.weight_decay,\n",
    "    )\n",
    "\n",
    "    early_stopper = None\n",
    "    if config.training.early_stopping_patience:\n",
    "        early_stopper = EarlyStopper(patience=config.training.early_stopping_patience)\n",
    "\n",
    "    train_info.timer.start_training()\n",
    "\n",
    "    for e in range(1, num_epochs + 1):\n",
    "        train_info.epoch = e\n",
    "        train_info.timer.start_epoch()\n",
    "        for t_i in train_infos:\n",
    "            print(t_i)\n",
    "        print(train_info)\n",
    "\n",
    "        if (not config.model.release_fixed_weights_after is None) and (\n",
    "            e > config.model.release_fixed_weights_after\n",
    "        ):\n",
    "            model, optimizer = set_weights_trainable(\n",
    "                model.backbone[0].body, optimizer, None\n",
    "            )\n",
    "\n",
    "        train_logger = train_one_epoch(\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_dataloader,\n",
    "            device=device,\n",
    "            epoch=train_info.epoch,\n",
    "        )\n",
    "\n",
    "        train_info.train_losses.append(train_logger.get_data())\n",
    "        model.eval()\n",
    "\n",
    "        val_logger, val_evaluator = evaluate(\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            data_loader=val_dataloader,\n",
    "            postprocessors=postprocessors,\n",
    "            device=device,\n",
    "            return_evaluator=True,\n",
    "        )\n",
    "\n",
    "        train_info.val_losses.append(val_logger.get_data())\n",
    "        clear_output()\n",
    "        plot_losses(\n",
    "            train_info.train_losses,\n",
    "            train_info.val_losses,\n",
    "        )\n",
    "        epoch_end_print(train_info, early_stopper, num_epochs)\n",
    "\n",
    "        if early_stopper and train_info.epoch > config.training.warmup_epoch:\n",
    "            train_info = check_best(\n",
    "                train_info=train_info,\n",
    "                model=model,\n",
    "                optimiser=optimizer,\n",
    "                val_evaluator=val_evaluator,\n",
    "            )\n",
    "            to_stop = early_stopper.early_stop(train_info.val_losses[-1][\"loss\"])\n",
    "            if to_stop:\n",
    "                print(\n",
    "                    f\"| Patience reached [{early_stopper.counter}], EarlyStopping end |\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "    train_info = end_train(\n",
    "        train_info=train_info,\n",
    "        model=model,\n",
    "        optimiser=optimizer,\n",
    "        val_evaluator=val_evaluator,\n",
    "    )\n",
    "\n",
    "    train_infos.append(train_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in train_infos :\n",
    "    print(t)\n",
    "    plot_losses(\n",
    "        t.train_losses,\n",
    "        t.val_losses,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all train_infos on the best\n",
    "from utils.checkpoint import load_checkpoints\n",
    "from engine.lesion_detection import get_ap_ar\n",
    "\n",
    "performances = {}\n",
    "\n",
    "for t in train_infos:\n",
    "    train_info, cp = load_checkpoints(t.best_val_loss_model_path, device)\n",
    "    config = train_info.config\n",
    "\n",
    "    model, criterion, postprocessors = build_detr(\n",
    "        backbone=\"resnet18\",\n",
    "        train_backbone=\"true\",\n",
    "        hidden_dim=config.model.hidden_dim,\n",
    "        dilation=config.model.dilation,\n",
    "        position_embedding=config.model.position_embedding,\n",
    "        dropout=config.model.dropout,\n",
    "        nheads=config.model.nheads,\n",
    "        dim_feedforward=config.model.dim_feedforward,\n",
    "        enc_layers=config.model.enc_layers,\n",
    "        dec_layers=config.model.dec_layers,\n",
    "        pre_norm=config.model.pre_norm,\n",
    "        num_classes=len(config.dataset.label_cols),\n",
    "        num_queries=config.model.num_queries,\n",
    "        aux_loss=config.model.aux_loss,\n",
    "        set_cost_class=config.model.set_cost_class,\n",
    "        set_cost_bbox=config.model.set_cost_bbox,\n",
    "        set_cost_giou=config.model.set_cost_giou,\n",
    "        giou_loss_coef=config.model.giou_loss_coef,\n",
    "        bbox_loss_coef=config.model.bbox_loss_coef,\n",
    "        eos_coef=config.model.eos_coef,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # weights.\n",
    "    backbone = load_backbone(config, device)\n",
    "    model.backbone[0].body = backbone.body\n",
    "    model.to(device)\n",
    "    model.load_state_dict(cp[\"model\"])\n",
    "    model.eval()\n",
    "\n",
    "    dataset_args = {\n",
    "        \"df_path\": os.path.join(\"spreadsheets\", \"reflacx.csv\"),\n",
    "        \"mimic_eye_path\": d_path.MIMIC_EYE_PATH,\n",
    "        \"image_size\": config.dataset.image_size,\n",
    "        \"label_cols\": config.dataset.label_cols,\n",
    "    }\n",
    "\n",
    "    _, _, test_dataset = get_datasets(\n",
    "        dataset_args=dataset_args,\n",
    "        dataset_class=REFLACXLesionDetectionDataset,\n",
    "    )\n",
    "\n",
    "    _, _, test_dataloader = get_dataloaders(\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        test_dataset,\n",
    "        batch_size=config.training.batch_size,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    _, test_evaluator = evaluate(\n",
    "        criterion=criterion,\n",
    "        postprocessors=postprocessors,\n",
    "        model=model,\n",
    "        data_loader=test_dataloader,\n",
    "        device=device,\n",
    "        return_evaluator=True,\n",
    "    )\n",
    "\n",
    "    performance_dict = get_ap_ar(\n",
    "        test_evaluator.coco_eval[\"bbox\"],\n",
    "    )\n",
    "\n",
    "    print(t)\n",
    "    print(performance_dict)\n",
    "\n",
    "    performances[f\"{config.training.name} - {config.model.name}\"] = performance_dict\n",
    "\n",
    "    with open(\n",
    "        os.path.join(\"checkpoints\", t.best_val_loss_model_path, \"performance.txt\"), \"w\"\n",
    "    ) as f:\n",
    "        f.write(str(t) + \"\\n\" + \"Best: \\n\" + str(performance_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df = pd.DataFrame(performances).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {}\n",
    "for n, p in model.named_parameters():\n",
    "    param_dict.update({n: {\"#params\":p.nelement()}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(param_dict).transpose().sort_values(\"#params\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
